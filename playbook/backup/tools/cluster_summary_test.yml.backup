---
# cluster_summary_new.yml - Collects information about all nodes in an Elasticsearch cluster

# Task 1: Setup variables
- name: Set base variables for the cluster summary
  set_fact:
    deployment_dir: "{{ lookup('env', 'HOME') }}/.elasticsearch"
    services:
      - elasticsearch
      - kibana
      - filebeat
      - metricbeat
    timestamp: "{{ ansible_date_time.iso8601 }}"
  run_once: true

# Task 2: Load deployment variables if available
- name: Load deployment variables if available
  include_vars:
    file: "{{ deployment_dir }}/deployment_vars.yml"
  ignore_errors: yes
  run_once: true

# Task 3: Initialize per-host data collection
- name: Initialize host_data for this host
  set_fact:
    host_data:
      hostname: "{{ inventory_hostname }}"
      ip: "{{ ansible_host | default(ansible_default_ipv4.address) | default('unknown') }}"
      components: {}
      resources:
        memory_total_mb: "{{ ansible_memory_mb.real.total | default(0) }}"
        memory_free_mb: "{{ ansible_memory_mb.real.free | default(0) }}"
        cpu_count: "{{ ansible_processor_vcpus | default(ansible_processor_count) | default(0) }}"
        disk_total_gb: "{{ (ansible_mounts | selectattr('mount', 'equalto', '/') | map(attribute='size_total') | list | first | int / 1024 / 1024 / 1024) | round(2) | default(0) }}"
        disk_free_gb: "{{ (ansible_mounts | selectattr('mount', 'equalto', '/') | map(attribute='size_available') | list | first | int / 1024 / 1024 / 1024) | round(2) | default(0) }}"

# Task 4: Check package installation status
- name: Check package installation status
  shell: "dpkg-query -W -f='${Status}' {{ item }} 2>/dev/null | grep -q 'install ok installed' && echo installed || echo not_installed"
  register: pkg_status
  changed_when: false
  failed_when: false
  with_items:
    - elasticsearch
    - kibana
    - filebeat
    - metricbeat
  become: yes

# Task 5: Check service status
- name: Check service status
  service_facts:
  register: service_facts
  become: yes

# Task 6: Gather component data for each service
- name: Gather component data for each service
  set_fact:
    host_data: "{{ host_data | combine({
      'components': {
        'elasticsearch': {
          'installed': pkg_status.results[0].stdout == 'installed',
          'status': (pkg_status.results[0].stdout == 'installed' and 'elasticsearch.service' in service_facts.ansible_facts.services) | ternary(service_facts.ansible_facts.services['elasticsearch.service'].state, 'not_installed')
        },
        'kibana': {
          'installed': pkg_status.results[1].stdout == 'installed',
          'status': (pkg_status.results[1].stdout == 'installed' and 'kibana.service' in service_facts.ansible_facts.services) | ternary(service_facts.ansible_facts.services['kibana.service'].state, 'not_installed')
        },
        'filebeat': {
          'installed': pkg_status.results[2].stdout == 'installed',
          'status': (pkg_status.results[2].stdout == 'installed' and 'filebeat.service' in service_facts.ansible_facts.services) | ternary(service_facts.ansible_facts.services['filebeat.service'].state, 'not_installed')
        },
        'metricbeat': {
          'installed': pkg_status.results[3].stdout == 'installed',
          'status': (pkg_status.results[3].stdout == 'installed' and 'metricbeat.service' in service_facts.ansible_facts.services) | ternary(service_facts.ansible_facts.services['metricbeat.service'].state, 'not_installed')
        }
      }
    }, recursive=true) }}"

# Task 7: Get Elasticsearch version info if installed
- name: Get Elasticsearch version info
  shell: "grep -s 'Build' /var/log/elasticsearch/gc.log | grep -oE '[0-9]+\\.[0-9]+\\.[0-9]+' | head -1 || echo unknown"
  register: es_version_output
  changed_when: false
  failed_when: false
  when: host_data.components.elasticsearch.installed | bool
  become: yes

# Task 8: Check Elasticsearch data directory
- name: Check Elasticsearch data directory
  stat:
    path: "/var/lib/elasticsearch"
  register: es_data_dir
  when: host_data.components.elasticsearch.installed | bool
  become: yes

# Task 9: Get data directory disk usage
- name: Get data directory disk usage
  shell: "du -sh /var/lib/elasticsearch 2>/dev/null | cut -f1 || echo 'unknown'"
  register: es_data_usage
  changed_when: false
  failed_when: false
  when: host_data.components.elasticsearch.installed | bool and es_data_dir.stat.exists | default(false) | bool
  become: yes

# Task 10: Add Elasticsearch version and data info
- name: Add Elasticsearch version and data info
  set_fact:
    host_data: "{{ host_data | combine({
      'components': {
        'elasticsearch': host_data.components.elasticsearch | combine({
          'version': es_version_output.stdout | default('unknown'),
          'data_dir_exists': es_data_dir.stat.exists | default(false) | bool,
          'data_usage': es_data_usage.stdout | default('unknown')
        })
      }
    }, recursive=true) }}"
  when: host_data.components.elasticsearch.installed | bool

# Task 11: Register host data with controller
- name: Register host data with controller
  set_fact:
    node_data_{{ inventory_hostname | replace('.', '_') | replace('-', '_') }}: "{{ host_data }}"
  run_once: false
  delegate_facts: true

# Task 12: Gather all host data together
- name: Gather all nodes data
  set_fact:
    nodes: "{{ nodes | default([]) + [host_data] }}"
  run_once: true

# Task 13: Calculate topology
- name: Analyze cluster topology
  set_fact:
    topology:
      master_nodes: "{{ groups['master_nodes'] | default([]) | length }}"
      hot_nodes: "{{ groups['hot_nodes'] | default([]) | length }}"
      warm_nodes: "{{ groups['warm_nodes'] | default([]) | length if 'warm_nodes' in groups else 0 }}"
      cold_nodes: "{{ groups['cold_nodes'] | default([]) | length if 'cold_nodes' in groups else 0 }}"
      frozen_nodes: "{{ groups['frozen_nodes'] | default([]) | length if 'frozen_nodes' in groups else 0 }}"
      ml_nodes: "{{ groups['ml_nodes'] | default([]) | length if 'ml_nodes' in groups else 0 }}"
      kibana: "{{ groups['kibana'] | default([]) | length }}"
      monitoring_instance: "{{ groups['monitoring_instance'] | default([]) | length if 'monitoring_instance' in groups else 0 }}"
      helper_instance: "{{ groups['helper_instance'] | default([]) | length }}"
      total_hosts: "{{ groups['all'] | length }}"
  run_once: true

# Task 14: Initialize service counts
- name: Initialize service count data
  set_fact:
    service_counts:
      elasticsearch:
        total: 0
        running: 0
        stopped: 0
        failed: 0
        not_installed: 0
      kibana:
        total: 0
        running: 0
        stopped: 0
        failed: 0
        not_installed: 0
      filebeat:
        total: 0
        running: 0
        stopped: 0
        failed: 0
        not_installed: 0
      metricbeat:
        total: 0
        running: 0
        stopped: 0
        failed: 0
        not_installed: 0
  run_once: true

# Task 15: Calculate service counts from all hosts - Build directly from node list
- name: Gather all node data first
  set_fact:
    all_nodes: "{{ groups['all'] | map('extract', hostvars) | selectattr('host_data', 'defined') | map(attribute='host_data') | list }}"
  run_once: true

- name: Count services on all nodes
  set_fact:
    service_counts: "{{ service_counts | combine({
      item: {
        'total': (all_nodes | selectattr('components.' + item + '.installed', 'defined') | selectattr('components.' + item + '.installed') | list | length),
        'running': (all_nodes | selectattr('components.' + item + '.status', 'defined') | selectattr('components.' + item + '.status', 'equalto', 'running') | list | length),
        'stopped': (all_nodes | selectattr('components.' + item + '.status', 'defined') | selectattr('components.' + item + '.status', 'equalto', 'stopped') | list | length),
        'failed': (all_nodes | selectattr('components.' + item + '.status', 'defined') | selectattr('components.' + item + '.status', 'equalto', 'failed') | list | length),
        'not_installed': (topology.total_hosts | int - (all_nodes | selectattr('components.' + item + '.installed', 'defined') | selectattr('components.' + item + '.installed') | list | length))
      }
    }, recursive=true) }}"
  loop: "{{ services }}"
  run_once: true

# Task 16: Not needed anymore, moved to previous task

# Task 17: Get Elasticsearch nodes
- name: Get Elasticsearch nodes
  set_fact:
    elasticsearch_nodes: []
  run_once: true

- name: Check if hot nodes exist
  set_fact:
    has_hot_nodes: "{{ groups['hot_nodes'] is defined and groups['hot_nodes'] | length > 0 }}"
  run_once: true

# Task 18: Direct password loading like in post_deploy.yml
- name: Load elastic password directly
  set_fact:
    elastic_password: "{{ lookup('file', lookup('env', 'HOME') + '/.elasticsearch/elastic_password.txt') | trim }}"
  run_once: true
  when: has_hot_nodes
  ignore_errors: yes
  no_log: true

# Task 20: Try to get cluster health with approach from post_deploy.yml
- name: Try to get cluster health with retries
  uri:
    url: "https://{{ hostvars[groups['hot_nodes'][0]]['ansible_host'] }}:9200/_cluster/health"
    method: GET
    user: elastic
    password: "{{ elastic_password }}"
    force_basic_auth: yes
    validate_certs: no
    return_content: yes
  register: es_health
  until: es_health.status == 200
  retries: 3
  delay: 5
  ignore_errors: yes
  when: has_hot_nodes
  no_log: false
  run_once: true
  
- name: Get detailed cluster information
  uri:
    url: "https://{{ hostvars[groups['hot_nodes'][0]]['ansible_host'] }}:9200/_cat/nodes?v&h=name,ip,node.role,version,master,disk.total,disk.used_percent,heap.percent,ram.percent,cpu&s=name"
    method: GET
    user: elastic
    password: "{{ elastic_password }}"
    force_basic_auth: yes
    validate_certs: no
    return_content: yes
  register: nodes_info
  ignore_errors: yes
  when: has_hot_nodes and es_health is defined and es_health.status == 200
  no_log: false
  run_once: true
  
- name: Debug ES health response
  debug:
    msg: 
      - "ES health response status: {{ es_health.status | default('undefined') }}"
      - "ES health error: {{ es_health.msg | default('no error message') }}"
      - "Nodes info: {{ nodes_info.content | default('not available') }}"
  when: es_health is defined
  run_once: true

# Task 21: Not needed anymore, already built in task 15

# Task 22: Create the summary report
- name: Create detailed summary report
  copy:
    dest: "/tmp/cluster_summary_report.txt"
    content: |
      CLUSTER SUMMARY REPORT
      =====================
      Generated: {{ timestamp }}

      CLUSTER TOPOLOGY CONFIGURATION (from inventory.ini)
      -------------------------------
      Total Hosts:    {{ topology.total_hosts }}
      Master Nodes:   {{ topology.master_nodes }}
      Hot Nodes:      {{ topology.hot_nodes }}
      Warm Nodes:     {{ topology.warm_nodes | default(0) }}
      Cold Nodes:     {{ topology.cold_nodes | default(0) }}
      Frozen Nodes:   {{ topology.frozen_nodes | default(0) }}
      ML Nodes:       {{ topology.ml_nodes | default(0) }}
      Kibana Nodes:   {{ topology.kibana }}
      {% if topology.monitoring_instance | int > 0 %}
      Monitoring:     {{ topology.monitoring_instance }}
      {% endif %}
      Helper Nodes:   {{ topology.helper_instance }}
      
      Note: Node counts reflect inventory configuration, not necessarily active nodes.

      LIVE SERVICE STATUS
      -------------
      Service        | Total | Running | Stopped | Failed | Not Installed
      -------------- | ----- | ------- | ------- | ------ | -------------
      {% for service in services %}
      {{ "%-14s" | format(service | capitalize) }} | {{ "%5s" | format(service_counts[service].total) }} | {{ "%7s" | format(service_counts[service].running) }} | {{ "%7s" | format(service_counts[service].stopped) }} | {{ "%6s" | format(service_counts[service].failed) }} | {{ "%13s" | format(service_counts[service].not_installed) }}
      {% endfor %}

      LIVE ELASTICSEARCH CLUSTER HEALTH
      --------------------------
      {% if es_health is defined and es_health.status == 200 %}
      Cluster: {{ es_health.json.cluster_name }}
      Status: {{ es_health.json.status }}
      Nodes: {{ es_health.json.number_of_nodes }}
      Data Nodes: {{ es_health.json.number_of_data_nodes }}
      Active Shards: {{ es_health.json.active_shards }}
      
      LIVE NODE DETAILS
      -----------
      Host                  | IP           | Role   | Version | Master | Disk Total | Disk Used % | Heap % | RAM % | CPU %
      --------------------- | ------------ | ------ | ------- | ------ | ---------- | ----------- | ------ | ----- | -----
      {% if nodes_info is defined and nodes_info.content is defined %}
      {% set lines = nodes_info.content.split('\n') %}
      {% for line in lines %}
      {% if loop.index > 1 and line.strip() %}
      {% set fields = line.split() %}
      {% if fields|length >= 10 %}
      {{ "%-20s" | format(fields[0]) }} | {{ "%-12s" | format(fields[1]) }} | {{ "%-6s" | format(fields[2]) }} | {{ "%-7s" | format(fields[3]) }} | {{ "%-6s" | format(fields[4]) }} | {{ "%10s" | format(fields[5]) }} | {{ "%11s" | format(fields[6]) }} | {{ "%6s" | format(fields[7]) }} | {{ "%5s" | format(fields[8]) }} | {{ "%5s" | format(fields[9]) }}
      {% endif %}
      {% endif %}
      {% endfor %}
      {% else %}
      Node details not available
      {% endif %}
      
      Node Role Legend:
        h = hot data node       i = ingest node       l = ML node       r = remote cluster client
        c = cold data node      m = master-eligible   d = data node     s = content/search node
        f = frozen data node    t = transform node    v = voting-only   w = warm data node
        
      Master Column Status:
        * = Current active master node (only one node will show this)
        - = All other nodes (including master-eligible nodes not currently active)
      {% else %}
      Not available: {{ "ES health check returned status " + es_health.status|string if es_health is defined and es_health.status is defined else "Unable to connect to Elasticsearch cluster API" }}
      {% endif %}

      LIVE SERVER NODE DETAILS
      ------------------
      Host                  | IP           | CPU | Memory Total/Free | Disk Total/Free    | ES  | KB  | FB  | MB  | ES Data
      --------------------- | ------------ | --- | ----------------- | ------------------ | --- | --- | --- | --- | --------
      {% for node in all_nodes | sort(attribute='hostname') %}
      {{ "%-20s" | format(node.hostname) }} | {{ "%-12s" | format(node.ip) }} | {{ "%3s" | format(node.resources.cpu_count) }} | {{ "%8s" | format(node.resources.memory_total_mb | int // 1024) }}GB/{{ "%-8s" | format(node.resources.memory_free_mb | int // 1024) }}GB | {{ "%8s" | format(node.resources.disk_total_gb) }}GB/{{ "%-8s" | format(node.resources.disk_free_gb) }}GB | {{ 'OK ' if node.components.elasticsearch.installed and node.components.elasticsearch.status == 'running' else 'NO ' }} | {{ 'OK ' if node.components.kibana.installed and node.components.kibana.status == 'running' else 'NO ' }} | {{ 'OK ' if node.components.filebeat.installed and node.components.filebeat.status == 'running' else 'NO ' }} | {{ 'OK ' if node.components.metricbeat.installed and node.components.metricbeat.status == 'running' else 'NO ' }} | {{ node.components.elasticsearch.data_usage if node.components.elasticsearch.installed and node.components.elasticsearch.data_dir_exists else 'N/A' }}
      {% endfor %}
      
      Legend: ES=Elasticsearch, KB=Kibana, FB=Filebeat, MB=Metricbeat
      Services: OK=Running, NO=Not Installed/Not Running
  run_once: true

# Task 23: Display the summary report
- name: Get report content
  command: cat /tmp/cluster_summary_report.txt
  register: report_content
  changed_when: false
  run_once: true

- name: Display summary report
  debug:
    msg: "{{ report_content.stdout_lines }}"
  run_once: true

# Task 24: Save report to ~/.elasticsearch directory on the controller machine
- name: Debug deployment dir
  debug:
    msg: "Deployment directory is: {{ deployment_dir }}"
  run_once: true
  delegate_to: localhost

- name: Ensure ~/.elasticsearch directory exists on controller
  file:
    path: "{{ lookup('env', 'HOME') }}/.elasticsearch"
    state: directory
    mode: '0755'
  run_once: true
  delegate_to: localhost

- name: Create backups directory if it doesn't exist on controller
  file:
    path: "{{ lookup('env', 'HOME') }}/.elasticsearch/backups"
    state: directory
    mode: '0755'
  run_once: true
  delegate_to: localhost

- name: Check if previous report exists on controller
  stat:
    path: "{{ lookup('env', 'HOME') }}/.elasticsearch/cluster_summary_latest.txt"
  register: previous_report
  run_once: true
  delegate_to: localhost

- name: Backup previous report if it exists on controller
  shell: "cp {{ lookup('env', 'HOME') }}/.elasticsearch/cluster_summary_latest.txt {{ lookup('env', 'HOME') }}/.elasticsearch/backups/cluster_summary_$(date +%Y%m%d%H%M%S).txt"
  when: previous_report.stat.exists
  run_once: true
  delegate_to: localhost

- name: Save current report to permanent location on controller
  copy:
    content: "Cluster Summary Report - Generated: {{ ansible_date_time.iso8601 }}\n\n{{ report_content.stdout }}"
    dest: "{{ lookup('env', 'HOME') }}/.elasticsearch/cluster_summary_latest.txt"
  register: save_result
  run_once: true
  delegate_to: localhost

- name: Debug save result
  debug:
    msg: "Report saved to: {{ lookup('env', 'HOME') }}/.elasticsearch/cluster_summary_latest.txt on the controller machine"
  run_once: true

# Task 25: Clean up temporary files
- name: Cleanup temporary files
  file:
    path: "/tmp/cluster_summary_report.txt"
    state: absent
  ignore_errors: yes
  run_once: true
