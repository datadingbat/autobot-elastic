---
# cluster_summary_new.yml - Collects information about all nodes in an Elasticsearch cluster

# Task 1: Setup variables
- name: Set base variables for the cluster summary
  set_fact:
    deployment_dir: "{{ lookup('env', 'HOME') }}/.elasticsearch"
    services:
      - elasticsearch
      - kibana
      - filebeat
      - metricbeat
    timestamp: "{{ ansible_date_time.iso8601 }}"
  run_once: true

# Task 2: Load deployment variables if available
- name: Load deployment variables if available
  include_vars:
    file: "{{ deployment_dir }}/deployment_vars.yml"
  ignore_errors: yes
  run_once: true

# Task 3: Initialize per-host data collection
- name: Initialize host_data for this host
  set_fact:
    host_data:
      hostname: "{{ inventory_hostname }}"
      ip: "{{ hostvars[inventory_hostname]['ansible_host'] | default(ansible_default_ipv4.address) | default('?') }}"
      components: {}
      resources:
        memory_total_mb: "{{ ansible_memory_mb.real.total | default(0) if ansible_memory_mb is defined and ansible_memory_mb.real is defined else 0 }}"
        memory_free_mb: "{{ ansible_memory_mb.real.free | default(0) if ansible_memory_mb is defined and ansible_memory_mb.real is defined else 0 }}"
        cpu_count: "{{ ansible_processor_vcpus | default(ansible_processor_count) | default(0) }}"
        disk_total_gb: "{{ (ansible_mounts | selectattr('mount', 'equalto', '/') | map(attribute='size_total') | list | first | int / 1024 / 1024 / 1024) | round(2) | default(0) if ansible_mounts is defined else 0 }}"
        disk_free_gb: "{{ (ansible_mounts | selectattr('mount', 'equalto', '/') | map(attribute='size_available') | list | first | int / 1024 / 1024 / 1024) | round(2) | default(0) if ansible_mounts is defined else 0 }}"

# Task 4: Check package installation status
- name: Check package installation status
  shell: "dpkg-query -W -f='${Status}' {{ item }} 2>/dev/null | grep -q 'install ok installed' && echo installed || echo not_installed"
  register: pkg_status
  changed_when: false
  failed_when: false
  with_items:
    - elasticsearch
    - kibana
    - filebeat
    - metricbeat
  become: yes

# Task 5: Check service status
- name: Check service status
  service_facts:
  register: service_facts
  become: yes

# Task 6: Gather component data for each service
- name: Gather component data for each service
  set_fact:
    host_data: "{{ host_data | combine({
      'components': {
        'elasticsearch': {
          'installed': pkg_status.results[0].stdout == 'installed',
          'status': (pkg_status.results[0].stdout == 'installed' and 'elasticsearch.service' in service_facts.ansible_facts.services) | ternary(service_facts.ansible_facts.services['elasticsearch.service'].state, 'not_installed')
        },
        'kibana': {
          'installed': pkg_status.results[1].stdout == 'installed',
          'status': (pkg_status.results[1].stdout == 'installed' and 'kibana.service' in service_facts.ansible_facts.services) | ternary(service_facts.ansible_facts.services['kibana.service'].state, 'not_installed')
        },
        'filebeat': {
          'installed': pkg_status.results[2].stdout == 'installed',
          'status': (pkg_status.results[2].stdout == 'installed' and 'filebeat.service' in service_facts.ansible_facts.services) | ternary(service_facts.ansible_facts.services['filebeat.service'].state, 'not_installed')
        },
        'metricbeat': {
          'installed': pkg_status.results[3].stdout == 'installed',
          'status': (pkg_status.results[3].stdout == 'installed' and 'metricbeat.service' in service_facts.ansible_facts.services) | ternary(service_facts.ansible_facts.services['metricbeat.service'].state, 'not_installed')
        }
      }
    }, recursive=true) }}"

# Task 7: Get Elasticsearch version info if installed
- name: Get Elasticsearch version info
  shell: "grep -s 'Build' /var/log/elasticsearch/gc.log | grep -oE '[0-9]+\\.[0-9]+\\.[0-9]+' | head -1 || echo unknown"
  register: es_version_output
  changed_when: false
  failed_when: false
  when: host_data.components.elasticsearch.installed | bool
  become: yes

# Task 8: Check Elasticsearch data directory
- name: Check Elasticsearch data directory
  stat:
    path: "/var/lib/elasticsearch"
  register: es_data_dir
  when: host_data.components.elasticsearch.installed | bool
  become: yes

# Task 9: Get data directory disk usage
- name: Get data directory disk usage
  shell: "du -sh /var/lib/elasticsearch 2>/dev/null | cut -f1 || echo 'unknown'"
  register: es_data_usage
  changed_when: false
  failed_when: false
  when: host_data.components.elasticsearch.installed | bool and es_data_dir.stat.exists | default(false) | bool
  become: yes

# Task 10: Add Elasticsearch version and data info
- name: Add Elasticsearch version and data info
  set_fact:
    host_data: "{{ host_data | combine({
      'components': {
        'elasticsearch': host_data.components.elasticsearch | combine({
          'version': es_version_output.stdout | default('unknown'),
          'data_dir_exists': es_data_dir.stat.exists | default(false) | bool,
          'data_usage': es_data_usage.stdout | default('unknown')
        })
      }
    }, recursive=true) }}"
  when: host_data.components.elasticsearch.installed | bool

# Task 11: Register host data with controller
- name: Register host data with controller
  set_fact:
    node_data_{{ inventory_hostname | replace('.', '_') | replace('-', '_') }}: "{{ host_data }}"
  run_once: false
  delegate_facts: true

# Task 12: Gather all host data together
- name: Gather all nodes data
  set_fact:
    nodes: "{{ nodes | default([]) + [host_data] }}"
  run_once: true

# Task 13: Calculate topology
- name: Analyze cluster topology
  set_fact:
    topology:
      master_nodes: "{{ groups['master_nodes'] | default([]) | length }}"
      hot_nodes: "{{ groups['hot_nodes'] | default([]) | length }}"
      warm_nodes: "{{ groups['warm_nodes'] | default([]) | length if 'warm_nodes' in groups else 0 }}"
      cold_nodes: "{{ groups['cold_nodes'] | default([]) | length if 'cold_nodes' in groups else 0 }}"
      frozen_nodes: "{{ groups['frozen_nodes'] | default([]) | length if 'frozen_nodes' in groups else 0 }}"
      ml_nodes: "{{ groups['ml_nodes'] | default([]) | length if 'ml_nodes' in groups else 0 }}"
      kibana: "{{ groups['kibana'] | default([]) | length }}"
      monitoring_instance: "{{ groups['monitoring_instance'] | default([]) | length if 'monitoring_instance' in groups else 0 }}"
      helper_instance: "{{ groups['helper_instance'] | default([]) | length }}"
      total_hosts: "{{ groups['all'] | length }}"
  run_once: true

# Task 14: Initialize service counts
- name: Initialize service count data
  set_fact:
    service_counts:
      elasticsearch:
        total: 0
        running: 0
        stopped: 0
        failed: 0
        not_installed: 0
      kibana:
        total: 0
        running: 0
        stopped: 0
        failed: 0
        not_installed: 0
      filebeat:
        total: 0
        running: 0
        stopped: 0
        failed: 0
        not_installed: 0
      metricbeat:
        total: 0
        running: 0
        stopped: 0
        failed: 0
        not_installed: 0
  run_once: true

# Task 15: Calculate service counts from all hosts - Build directly from node list
- name: Gather all node data first
  set_fact:
    all_nodes: "{{ groups['all'] | map('extract', hostvars) | selectattr('host_data', 'defined') | map(attribute='host_data') | list }}"
  run_once: true

- name: Count services on all nodes
  set_fact:
    service_counts: "{{ service_counts | combine({
      item: {
        'total': (all_nodes | selectattr('components.' + item + '.installed', 'defined') | selectattr('components.' + item + '.installed') | list | length),
        'running': (all_nodes | selectattr('components.' + item + '.status', 'defined') | selectattr('components.' + item + '.status', 'equalto', 'running') | list | length),
        'stopped': (all_nodes | selectattr('components.' + item + '.status', 'defined') | selectattr('components.' + item + '.status', 'equalto', 'stopped') | list | length),
        'failed': (all_nodes | selectattr('components.' + item + '.status', 'defined') | selectattr('components.' + item + '.status', 'equalto', 'failed') | list | length),
        'not_installed': (topology.total_hosts | int - (all_nodes | selectattr('components.' + item + '.installed', 'defined') | selectattr('components.' + item + '.installed') | list | length))
      }
    }, recursive=true) }}"
  loop: "{{ services }}"
  run_once: true

# Task 16: Not needed anymore, moved to previous task

# Task 17: Get Elasticsearch nodes
- name: Get Elasticsearch nodes
  set_fact:
    elasticsearch_nodes: []
  run_once: true

- name: Check if hot nodes exist
  set_fact:
    has_hot_nodes: "{{ groups['hot_nodes'] is defined and groups['hot_nodes'] | length > 0 }}"
  run_once: true

# Task 18: Direct password loading like in post_deploy.yml
- name: Load elastic password directly
  set_fact:
    elastic_password: "{{ lookup('file', lookup('env', 'HOME') + '/.elasticsearch/elastic_password.txt') | trim }}"
  run_once: true
  when: has_hot_nodes
  ignore_errors: yes
  no_log: true

# Task 20: Try to get cluster health with approach from post_deploy.yml
- name: Try to get cluster health with retries
  uri:
    url: "https://{{ hostvars[groups['hot_nodes'][0]]['ansible_host'] }}:9200/_cluster/health"
    method: GET
    user: elastic
    password: "{{ elastic_password }}"
    force_basic_auth: yes
    validate_certs: no
    return_content: yes
  register: es_health
  until: es_health.status == 200
  retries: 3
  delay: 5
  ignore_errors: yes
  when: has_hot_nodes
  no_log: false
  run_once: true
  
- name: Get detailed cluster information
  uri:
    url: "https://{{ hostvars[groups['hot_nodes'][0]]['ansible_host'] }}:9200/_cat/nodes?v&h=name,ip,node.role,version,master,disk.total,disk.used_percent,heap.percent,ram.percent,cpu&s=name"
    method: GET
    user: elastic
    password: "{{ elastic_password }}"
    force_basic_auth: yes
    validate_certs: no
    return_content: yes
  register: nodes_info
  ignore_errors: yes
  when: has_hot_nodes and es_health is defined and es_health.status == 200
  no_log: false
  run_once: true
  
- name: Debug ES health response
  debug:
    msg: 
      - "ES health response status: {{ es_health.status | default('undefined') }}"
      - "ES health error: {{ es_health.msg | default('no error message') }}"
      - "Nodes info: {{ nodes_info.content | default('not available') }}"
  when: es_health is defined
  run_once: true

# Task 21: Not needed anymore, already built in task 15

# Task 22: Create the summary report
- name: Create detailed summary report
  copy:
    dest: "/tmp/cluster_summary_report.txt"
    content: |
      CLUSTER SUMMARY REPORT
      =====================
      Generated: {{ timestamp }}

      CLUSTER TOPOLOGY CONFIGURATION (from inventory.ini)
      -------------------------------
      Total Hosts:    {{ topology.total_hosts }}
      Master Nodes:   {{ topology.master_nodes }}
      Hot Nodes:      {{ topology.hot_nodes }}
      Warm Nodes:     {{ topology.warm_nodes | default(0) }}
      Cold Nodes:     {{ topology.cold_nodes | default(0) }}
      Frozen Nodes:   {{ topology.frozen_nodes | default(0) }}
      ML Nodes:       {{ topology.ml_nodes | default(0) }}
      Kibana Nodes:   {{ topology.kibana }}
      {% if topology.monitoring_instance | int > 0 %}
      Monitoring:     {{ topology.monitoring_instance }}
      {% endif %}
      Helper Nodes:   {{ topology.helper_instance }}
      
      Note: Node counts reflect inventory configuration, not necessarily active nodes.
      Note: Only nodes running Elasticsearch are included in node tables.

      LIVE SERVICE STATUS
      -------------
      Service        | Total | Running | Stopped | Failed | Not Installed
      -------------- | ----- | ------- | ------- | ------ | -------------
      {% for service in services %}
      {{ "%-14s" | format(service | capitalize) }} | {{ "%5s" | format(service_counts[service].total) }} | {{ "%7s" | format(service_counts[service].running) }} | {{ "%7s" | format(service_counts[service].stopped) }} | {{ "%6s" | format(service_counts[service].failed) }} | {{ "%13s" | format(service_counts[service].not_installed) }}
      {% endfor %}

      LIVE ELASTICSEARCH CLUSTER HEALTH
      --------------------------
      {% if es_health is defined and es_health.status == 200 %}
      Cluster: {{ es_health.json.cluster_name }}
      Status: {{ es_health.json.status }}
      Nodes: {{ es_health.json.number_of_nodes }}
      Data Nodes: {{ es_health.json.number_of_data_nodes }}
      Active Shards: {{ es_health.json.active_shards }}
      
      LIVE NODE DETAILS
      -----------
      {% if nodes_info is defined and nodes_info.content is defined %}
      {% set lines = nodes_info.content.split('\n') %}
      {% set max_host_len = 23 %}
      {% for line in lines %}
      {% if loop.index > 1 and line.strip() %}
      {% set fields = line.split() %}
      {% if fields|length >= 10 and fields[0]|length > max_host_len %}
      {% set max_host_len = fields[0]|length %}
      {% endif %}
      {% endif %}
      {% endfor %}
      {% set max_host_len = [max_host_len, 23]|max + 1 %}  {# Add 1 for safety padding #}
      {% set header_padding = "-" * max_host_len %}
      {% set host_padded = "Host" + " " * (max_host_len - 4) %}
      {{ host_padded }} | IP           | Role   | Version | Master | Disk Total | Disk Used % | Heap % | RAM % | CPU %
      {{ ("-" * max_host_len) }} | ------------ | ------ | ------- | ------ | ---------- | ----------- | ------ | ----- | -----
      {% for line in lines %}
      {% if loop.index > 1 and line.strip() %}
      {% set fields = line.split() %}
      {% if fields|length >= 10 %}
      {# Use a consistent width that's safely larger than needed #}
      {% set field0 = fields[0] + " " * (max_host_len - fields[0]|length) %}
              {% set field1 = fields[1] + " " * (12 - fields[1]|length) %}
              {% set field2 = fields[2] + " " * (6 - fields[2]|length) %}
              {% set field3 = fields[3] + " " * (7 - fields[3]|length) %}
              {% set field4 = fields[4] + " " * (6 - fields[4]|length) %}
              {% set field5 = fields[5] + " " * (10 - fields[5]|length) %}
              {% set field6 = fields[6] + " " * (11 - fields[6]|length) %}
              {% set field7 = fields[7] + " " * (6 - fields[7]|length) %}
              {% set field8 = fields[8] + " " * (5 - fields[8]|length) %}
              {% set field9 = fields[9] + " " * (5 - fields[9]|length) %}
              {{ field0 }} | {{ field1 }} | {{ field2 }} | {{ field3 }} | {{ field4 }} | {{ field5 }} | {{ field6 }} | {{ field7 }} | {{ field8 }} | {{ field9 }}
      {% endif %}
      {% endif %}
      {% endfor %}
      {% else %}
      Node details not available
      {% endif %}
      
      Node Role Legend:
        h = hot data node       i = ingest node       l = ML node       r = remote cluster client
        c = cold data node      m = master-eligible   d = data node     s = content/search node
        f = frozen data node    t = transform node    v = voting-only   w = warm data node
        
      Master Column Status:
        * = Current active master node (only one node will show this)
        - = All other nodes (including master-eligible nodes not currently active)
      {% else %}
      Not available: {{ "ES health check returned status " + es_health.status|string if es_health is defined and es_health.status is defined else "Unable to connect to Elasticsearch cluster API" }}
      {% endif %}

      LIVE SERVER NODE DETAILS (Elasticsearch Data Nodes Only)
      ------------------
      {% set max_host_len = 23 %}
      {% set elasticsearch_nodes = [] %}
      {% for node in all_nodes %}
        {% if node.components.elasticsearch.installed and node.hostname not in groups['helper_instance'] %}
          {% set elasticsearch_nodes = elasticsearch_nodes + [node] %}
          {% if node.hostname|length > max_host_len %}
            {% set max_host_len = node.hostname|length %}
          {% endif %}
        {% endif %}
      {% endfor %}
      {% set max_host_len = [max_host_len, 23]|max + 1 %}  {# Add 1 for safety padding #}
      {% set host_padded = "Host" + " " * (max_host_len - 4) %}
      {{ host_padded }} | IP           | Role | CPU | Memory (GB)  | Disk (GB)      | ES  | KB  | FB  | MB  | ES Data
      {{ ("-" * max_host_len) }} | ------------ | ---- | --- | ------------ | -------------- | --- | --- | --- | --- | -------
      {% for node in elasticsearch_nodes | sort(attribute='hostname') %}
      {% set mem_total = node.resources.memory_total_mb | int // 1024 %}
      {% set mem_free = node.resources.memory_free_mb | int // 1024 %}
      {% set disk_total = node.resources.disk_total_gb | float | round(2) %}
      {% set disk_free = node.resources.disk_free_gb | float | round(2) %}
      {% set node_role = '' %}
      {% if node.hostname in groups['master_nodes'] | default([]) %}{% set node_role = node_role + 'm' %}{% endif %}
      {% if node.hostname in groups['hot_nodes'] | default([]) %}{% set node_role = node_role + 'h' %}{% endif %}
      {% if node.hostname in groups['warm_nodes'] | default([]) %}{% set node_role = node_role + 'w' %}{% endif %}
      {% if node.hostname in groups['cold_nodes'] | default([]) %}{% set node_role = node_role + 'c' %}{% endif %}
      {% if node.hostname in groups['frozen_nodes'] | default([]) %}{% set node_role = node_role + 'f' %}{% endif %}
      {% if node.hostname in groups['ml_nodes'] | default([]) %}{% set node_role = node_role + 'l' %}{% endif %}
      {% if node_role == '' %}{% set node_role = '?' %}{% endif %}
      {% set hostname_padded = node.hostname + " " * (max_host_len - node.hostname|length) %}
      {% set ip_padded = node.ip + " " * (12 - node.ip|length) %}
      {% set role_padded = node_role + " " * (4 - node_role|length) %}
      {% set cpu_count_str = node.resources.cpu_count | string %}
      {% set cpu_padded = " " * (3 - cpu_count_str|length) + cpu_count_str %}
      
      {% set mem_total_str = (mem_total if mem_total > 0 else '?') | string %}
      {% set mem_total_padded = " " * (4 - mem_total_str|length) + mem_total_str %}
      {% set mem_free_str = (mem_free if mem_free > 0 else '?') | string %}
      {% set mem_free_padded = mem_free_str + " " * (4 - mem_free_str|length) %}
      
      {% set disk_total_str = (disk_total if disk_total > 0 else '?') | string %}
      {% set disk_total_padded = " " * (6 - disk_total_str|length) + disk_total_str %}
      {% set disk_free_str = (disk_free if disk_free > 0 else '?') | string %}
      {% set disk_free_padded = disk_free_str + " " * (6 - disk_free_str|length) %}
      
      {{ hostname_padded }} | {{ ip_padded }} | {{ role_padded }} | {{ cpu_padded }} | {{ mem_total_padded }}/{{ mem_free_padded }} | {{ disk_total_padded }}/{{ disk_free_padded }} | {{ 'OK ' if node.components.elasticsearch.installed and node.components.elasticsearch.status == 'running' else 'NO ' }} | {{ 'OK ' if node.components.kibana.installed and node.components.kibana.status == 'running' else 'NO ' }} | {{ 'OK ' if node.components.filebeat.installed and node.components.filebeat.status == 'running' else 'NO ' }} | {{ 'OK ' if node.components.metricbeat.installed and node.components.metricbeat.status == 'running' else 'NO ' }} | {{ node.components.elasticsearch.data_usage if node.components.elasticsearch.installed and node.components.elasticsearch.data_dir_exists else 'N/A' }}
      {% endfor %}
      
      Note: This table only includes nodes with Elasticsearch installed. Helper/Kibana-only nodes are excluded.
      
      Legend: ES=Elasticsearch, KB=Kibana, FB=Filebeat, MB=Metricbeat
      Services: OK=Running, NO=Not Installed/Not Running
      Values: ?=Information not available or not applicable, N/A=Not applicable
      Roles: m=master, h=hot, w=warm, c=cold, f=frozen, l=ml, k=kibana, helper=helper node
  run_once: true

# Task 23: Display the summary report
- name: Get report content
  command: cat /tmp/cluster_summary_report.txt
  register: report_content
  changed_when: false
  run_once: true

- name: Display summary report
  debug:
    msg: "{{ report_content.stdout_lines }}"
  run_once: true

# Task 24: Save report to ~/.elasticsearch directory on the controller machine
- name: Debug deployment dir
  debug:
    msg: "Deployment directory is: {{ deployment_dir }}"
  run_once: true
  delegate_to: localhost

- name: Ensure ~/.elasticsearch directory exists on controller
  file:
    path: "{{ lookup('env', 'HOME') }}/.elasticsearch"
    state: directory
    mode: '0755'
  run_once: true
  delegate_to: localhost

- name: Create backups directory if it doesn't exist on controller
  file:
    path: "{{ lookup('env', 'HOME') }}/.elasticsearch/backups"
    state: directory
    mode: '0755'
  run_once: true
  delegate_to: localhost

- name: Check if previous report exists on controller
  stat:
    path: "{{ lookup('env', 'HOME') }}/.elasticsearch/cluster_summary_latest.txt"
  register: previous_report
  run_once: true
  delegate_to: localhost

- name: Backup previous report if it exists on controller
  shell: "cp {{ lookup('env', 'HOME') }}/.elasticsearch/cluster_summary_latest.txt {{ lookup('env', 'HOME') }}/.elasticsearch/backups/cluster_summary_$(date +%Y%m%d%H%M%S).txt"
  when: previous_report.stat.exists
  run_once: true
  delegate_to: localhost

- name: Save current report to permanent location on controller
  copy:
    content: "Cluster Summary Report - Generated: {{ ansible_date_time.iso8601 }}\n\n{{ report_content.stdout }}"
    dest: "{{ lookup('env', 'HOME') }}/.elasticsearch/cluster_summary_latest.txt"
  register: save_result
  run_once: true
  delegate_to: localhost

- name: Debug save result
  debug:
    msg: "Report saved to: {{ lookup('env', 'HOME') }}/.elasticsearch/cluster_summary_latest.txt on the controller machine"
  run_once: true

# Task 25: Clean up temporary files
- name: Cleanup temporary files
  file:
    path: "/tmp/cluster_summary_report.txt"
    state: absent
  ignore_errors: yes
  run_once: true
